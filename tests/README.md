# AI Tuber テストガイド

## テストの種類

### 1. ユニットテスト (`tests/unit/`)
個別のコンポーネントの動作を検証します。

```bash
pytest tests/unit/
```

### 2. インテグレーションテスト (`tests/integration/`)
複数のコンポーネント間の連携を検証します。

```bash
pytest tests/integration/
```

### 3. 統合シナリオテスト (`tests/integration_test.py`)
AIエージェントの実際の動作シナリオを検証します（実LLM使用）。

**実行方法:**
```bash
# GOOGLE_API_KEYが必要
GOOGLE_API_KEY=your_api_key pytest tests/integration_test.py
```

**重要:** 
- このテストは実際のGemini APIを使用するため、API keyが必要です
- GitHub Actionsでは自動的にスキップされます
- **本番のペルソナをそのまま使用**してテストします（テスト用の特別な指示は追加しません）
- テストの検証:
  - `get_weather`ツールが呼ばれること（必須）
  - `speak`ツールが呼ばれること（必須）
  - 発話内容の具体的な文言はチェックしない（LLMの応答は変動するため）
- ペルソナ自体に「必ずspeakで応答すること」という明示的な指示を含めることで、本番環境でもテスト環境でも安定した動作を実現

### 4. E2Eテスト (`tests/e2e/`)
Dockerコンテナを起動してシステム全体の動作を検証します。

```bash
pytest tests/e2e/
```

## 全テストの実行

```bash
pytest
```

## カバレッジレポート

```bash
pytest --cov=src --cov-report=html
```

## テストの設計方針

### モック化の基準
- **外部API**: 完全にモック化（天気API等）
- **MCP通信**: テストレベルに応じてモック化
- **LLM**: 統合テストでは実LLMを使用し、ユニットテストではモック化

### 検証の優先度
1. **最優先**: ツールが正しく呼び出されること（`get_weather`, `speak`など）
2. **次優先**: 適切な引数でツールが呼ばれること
3. **対象外**: LLMの応答内容の具体的な文言（変動の可能性あり）

**重要な設計判断:**
- ツールの呼び出しパターンは必須検証（例: `get_weather` → `speak` の順序）
- LLMの応答文言は検証しない（例: 「晴れです」vs「良い天気です」の違いは許容）
- **ペルソナ自体に強い指示を含める**ことで、テスト用の特別な設定なしに安定した動作を保証
- テストは本番環境と同じ設定で実行され、実際のユーザー体験を反映
